{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  VAIC_23_24软件系统介绍："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAIC的软件分为两部分，在Jetson Nano上运行的python软件(目录：JetsonExample)和在VEX Brain上运行的C++软件(目录：V5Example)。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.基本概念说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先对VAIC程序中出现的AI的一些概念进行简单的解释：<br>\n",
    "\n",
    "### 1.深度神经网络的训练和推理：\n",
    "深度神经网络（DNN Deep Neural Networks）是一种由多层（即“深度”）的神经元组成的人工神经网络，用于从大量数据中学习复杂的模式和功能。<br>\n",
    "DNN的训练和推理是两个关键的过程，使网络能够执行各种任务，如图像识别、语音识别、自然语言处理等。以下是这两个过程的简单解释：<br>\n",
    "训练过程(training process)<br>\n",
    "训练是深度神经网络学习从输入数据到输出结果的映射的过程。训练涉及以下步骤：<br>\n",
    "数据准备：首先，必须收集并预处理训练数据，这包括标准化、归一化或其他形式的数据清洗和准备，以使数据适合神经网络处理。<br>\n",
    "前向传播：输入数据通过网络层被前向传递，每一层都应用激活函数（如ReLU、Sigmoid等），直到达到输出层。<br>\n",
    "损失计算：在输出层，根据网络的输出和实际期望输出（标签）计算损失值。损失函数（如交叉熵、均方误差）衡量了预测值和真实值之间的差异。<br>\n",
    "反向传播：利用梯度下降（或其他优化算法）调整网络权重，以最小化损失函数。这涉及计算损失函数关于每个权重的梯度，并根据这些梯度更新权重。<br>\n",
    "迭代优化：上述前向传播和反向传播的过程在多个周期（epochs）内重复进行，每次使用训练集中的不同批次（batch）的数据，直到网络性能达到满意的水 平或达到预设的迭代次数。向前传播如图1所示，向后传播如图2所示。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/前向过程.jpg\" width=\"500\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图1 向前传播过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推理过程(inference process)<br>\n",
    "推理是使用训练好的模型对新数据做出预测的过程。这通常发生在训练结束后，网络被部署用于实际应用。推理过程涉及以下步骤：<br>\n",
    "数据预处理：与训练阶段类似，推理输入数据需要进行适当的预处理。<br>\n",
    "前向传播：预处理后的数据被送入训练好的网络，进行一次前向传播运算，而不需要再进行反向传播或权重更新。<br>\n",
    "输出解释：网络的输出根据具体应用被解释和转换，例如，在分类任务中选择概率最高的类别。<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/反向过程.jpg\" width=\"500\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图2 反向传播过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练是建立模型的过程，需要大量的计算资源和数据，而推理则是使用这些模型进行预测的过程，通常要求速度快、效率高。<br> \n",
    "优化这两个过程是深度学习研究和应用的重要方面。下边会介绍在VAIC中使用了NVIDIA TensorRT加速软件进行推理过程的优化。<br>\n",
    "当前VAIC竞赛还处于初级阶段，竞赛中需要神经网络训练已由VEX AI官方训练完成并提供使用， 随着AI技术的普及和发展以及VAX AI比赛水平的提高，可能会出现允许和需要竞赛团队自己训练神经网络的可能。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.深度神经网络的开发平台的介绍：<br>\n",
    "脸书公司提供Pytorch和谷歌公司提供Tensorflow是当前最流行的深度学习框架，均为开源项目。<br>\n",
    "支持python语言，都提供了丰富的API和工具，支持各种深度学习模型的开发和训练。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/pytorch1.jpg\" width=\"500\" height=\"150\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch是一个开源的Python机器学习库，由Facebook人工智能研究院（FAIR）基于Torch推出，旨在提供灵活的深度学习框架。<br>\n",
    "核心功能：<br>\n",
    "PyTorch提供了两项核心功能：强大的GPU加速的张量计算（类似于NumPy），包含自动求导系统的深度神经网络。<br>\n",
    "主要特点：<br>\n",
    "动态计算图：PyTorch采用动态计算图的方式，允许在运行时构建和修改计算图，这使得实验和调试过程更加灵活。<br>\n",
    "灵活性：PyTorch提供了大量的灵活性，允许用户轻松地定义、训练和调试模型，并自由地定制自己的模型和训练流程。<br>\n",
    "易用性：PyTorch的API设计简单直观，易于学习和使用，使开发者能够快速上手并进行深度学习任务。<br>\n",
    "支持GPU加速：PyTorch可以利用GPU进行加速，加快深度学习模型的训练速度。<br>\n",
    "应用领域：<br>\n",
    "PyTorch在计算机视觉、自然语言处理和强化学习等领域都有广泛的应用。它提供了许多预训练的模型和工具库，如torchvision、torchtext和gym等，使得开发者可以更加方便地进行模型构建和调试。<br>\n",
    "环境支持：<br>\n",
    "PyTorch已兼容Windows（CUDA, CPU）、MacOS（CPU）和Linux（CUDA, ROCm, CPU）等多个操作系统和平台。<br>\n",
    "PyTorch的简洁性、高效性和易用性使其成为深度学习领域的重要工具之一，受到广大开发者和研究人员的青睐。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/tensorflow1.jpg\" width=\"500\" height=\"150\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow是一个开源的机器学习框架，由谷歌人工智能团队谷歌大脑（Google Brain）开发和维护。<br>\n",
    "以下是对TensorFlow的清晰简介：<br>\n",
    "主要特点：<br>\n",
    "高度灵活：支持各种机器学习和深度学习模型，包括神经网络、深度学习模型、强化学习等。<br>\n",
    "跨平台：支持在各类服务器、PC终端、移动设备和云服务器上运行。<br>\n",
    "高性能计算：通过GPU和TPU加速，实现高性能的计算和训练。<br>\n",
    "自动求导：提供自动求导功能，简化了模型训练的过程。<br>\n",
    "分布式计算：支持在多台机器上分布式计算，实现大规模数据和模型的训练。<br>\n",
    "可视化工具：提供TensorBoard工具，用于可视化模型的训练过程和结果。<br>\n",
    "社区支持：拥有庞大的社区，提供了丰富的文档、教程和示例代码，方便用户学习和使用。<br>\n",
    "环境支持：<br>\n",
    "Python TensorFlow提供CPU版本（tensorflow）和包含GPU加速的版本（tensorflow-gpu），以及它们的每日编译版本（tf-nightly、tf-nightly-gpu）。<br>\n",
    "应用领域：<br>\n",
    "TensorFlow广泛应用于机器学习、深度学习、自然语言处理、计算机视觉、强化学习、时间序列分析、推荐系统、语音识别等领域。<br>\n",
    "综上所述，TensorFlow是一个功能强大、灵活、跨平台、高性能的机器学习框架，广泛应用于各个领域的深度学习研究和应用中。<br>\n",
    "注：(tf-nightly、tf-nightly-gpu)是TensorFlow的一个每日构建版本，为开发者提供了一个预览和测试TensorFlow最新功能的机会。由于它可能包含不稳定的更改，因此在使用时需要谨慎，并确保在适当的环境中进行实验和测试。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.YOLOv3：\n",
    "前面已经简单地介绍过YOLOv3，这里需要进一步说明。<br>\n",
    "YOLOv3 是一个深度卷积神经网络，由总共 106 层组成。这包括多种不同类型的层，如卷积层、池化层、归一化层以及跳跃连接等。<br>\n",
    "其主体网络结构，称为 Darknet-53，Darknet-53 是一个开源的神经网络框架包含了 53 个卷积层， 最著名的应用是支持 YOLO系列的对象检测模型，是 YOLOv3 的基础。 <br>\n",
    "Darknet-53 是一个强大的特征提取器，包含了多次的残差连接，这些残差连接有助于防止在网络很深时出现的训练困难。残差网络通过允许输入直接连接到后面的层， 帮助优化梯度流，从而使得训练更深的网络变得可行。<br>\n",
    "在 Darknet-53 的基础上，YOLOv3 还加入了多尺度预测和上采样层，这使得网络能在三个不同的尺度上进行物体检测，提高了对小尺寸物体的检测能力。 这些额外的层使得整个网络结构的层数达到了106层。 这样的深层网络结构使得 YOLOv3 不仅在速度上表现出色，同时也在多种尺寸的物体检测任务中保持了很高的准确率。<br>\n",
    "YOLOv3模型在使用COCO数据集训练时，能够识别80种不同的类别，包括人、车辆、动物等。这是因为COCO（Common Objects in Context）数据集定义了 80种常见物体的类别。<br> \n",
    "需要说明的是VAIC的YOLOv3模型是在COCO数据集的基础上进行了微调，以适应VEX-5机器人竞赛的特殊场景，如竞赛场地、机器人结构、 运动部件、控制硬件、软件开发平台及传感器等。<br>\n",
    "对VAIC使用的YOLOv3模型加强对VEX-5机器人竞赛中常见的物体的识别， 如球、方块、三色球，以及颜色的识别，如红色、蓝色、绿色的物体等，例如在VAIC_23_24赛季使用的YOLOv3只需要进行三种三色球进行识别， 目录中的lable.txt文件中只有三种三色球的标签,GreenTriball,RedTriball，BlueTriball。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <img src=\"./image/banner-yolov3.png\" width=\"500\" height=\"150\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.GPU：GPU（Graphics Processing Unit，图形处理器）:<br>\n",
    "GPU是一种专用的电子计算设备，最初设计用于加速图像的创建，以便于快速输出到显示设备上。 随着技术的发展，GPU的功能已经从单纯的图形渲染扩展到复杂的计算任务，尤其是需要并行处理的AI任务。<br>\n",
    "主要特点和用途：<br>\n",
    "1. 并行处理能力：\n",
    "GPU拥有成百上千的核心，可以同时处理多个计算任务，这使得它在处理图形渲染、视频编辑、科学计算和机器学习等需要大量并行计算的任务时表现出色。<br>\n",
    "2. 图形渲染：<br>\n",
    "GPU最初和最基本的功能是加速图形渲染过程，它能快速处理复杂的图形和图像处理算法，实现高质量的视频游戏和3D动画效果。<br>\n",
    "3. 科学计算和机器学习：<br>\n",
    "随着计算需求的增加，GPU已经成为科学研究中不可或缺的工具，特别是在物理模拟、气候模型和生物信息学等领域。在机器学习和深度学习中，GPU可以大幅度加速模型训练过程，特别是在处理大规模数据集时。<br>\n",
    "4. 加速通用计算：<br>\n",
    "GPU的高并行处理能力也被用于加速广泛的通用计算任务，通过技术如CUDA（Compute Unified Device Architecture，统一计算架构） 和OpenCL（Open Computing Language，开放计算语言），开发者可以利用GPU执行非图形相关的计算任务。<br>\n",
    "NVIDIA提供的GPU在高性能计算和游戏领域具有广泛的影响力。<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/NVIDIA.jpeg\" width=\"500\" height=\"200\" alt=\"英伟达Jetson Nano\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.TensorRT(Tensor RealTime NVIDIA张量实时推理引擎):<br>\n",
    "NVIDIA的TensorRT是一个高性能深度学习推理（inference）引擎，TensorRT能够显著提升运行在NVIDIA GPU上的深度学习应用的性能和效率。 主要特性：<br>\n",
    "1. 优化：TensorRT通过图层和张量融合、精度校准（包括FP16和INT8支持）以及自动内核调优等技术，来优化深度学习模型的推理性能。<br>\n",
    "2. 多框架支持：它支持多种主流深度学习框架，如TensorFlow, PyTorch, Caffe等，使得从这些框架训练的模型可以直接转换为TensorRT优化后的模型。<br>\n",
    "3. 高效性能：TensorRT可以大幅提高模型的运行速度，降低延迟，特别适合需要实时处理的应用场景，如自动驾驶、机器人导航等。<br>\n",
    "4. 动态张量支持：支持动态输入，即在运行时根据需要改变输入的维度，这为各种应用提供了更大的灵活性。<br>\n",
    "5. 大规模部署：TensorRT支持在不同的NVIDIA硬件上运行，包括服务器和边缘设备，便于模型的大规模部署。<br>\n",
    "由于TensorRT具有通用的推理机制，在不用进行训练的情况下，可以直接使用训练完成的模型进行高速推理，不能安装TensorFlow, PyTorch等大型软件， 特别适合诸如Jetson Nano硬件资源相对贫乏的边缘计算设备。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 6.ONNX(开放神经网络交换协议)：<br>\n",
    "ONNX（Open Neural Network Exchange）是一个开放格式交换协议，用于深度学习模型参数的格式变换。这一格式使得模型可以在不同的机器学习和深度学习框架之间移植， 促进了模型的共享和部署。<br>\n",
    "ONNX由Facebook和Microsoft在2017年联合发起，并得到了包括Amazon、Google、IBM等多家大型科技公司的支持。<br>\n",
    "ONNX的主要特点： 框架互操作性：ONNX旨在允许开发者在一个框架（如TensorFlow、PyTorch等）中训练模型，并将其轻松地转换到其他框架中进行推理或进一步开发。<br> \n",
    "这样，开发者可以利用各个框架的特定优势，例如在一个框架中训练，在另一个框架中部署。<br>\n",
    "标准化的格式：ONNX定义了一组标准的操作和计算，以及一个标准的文件格式，用于描述在神经网络中常见的各种层和操作。<br> \n",
    "这种标准化有助于简化不同平台间的模型交换。<br>\n",
    "应用场景：<br>\n",
    "模型转换：开发者可以使用专门的转换工具（如ONNX Converter）将特定框架的模型转换为ONNX模型，进而转换到其他框架。<br>\n",
    "模型部署：ONNX模型可以被部署到支持ONNX的各种设备和平台上，包括服务器、移动设备、嵌入式设备等。<br>\n",
    "模型优化：ONNX提供了模型优化工具，可以对模型进行简化和加速，提高推理效率。<br>\n",
    "如何使用ONNX：<br>\n",
    "训练模型：在任何支持ONNX的框架(例如 Pytorch、Tensorflow等)中训练模型。<br>\n",
    "转换模型：使用相应的转换工具将模型转换为ONNX格式。<br>\n",
    "部署模型：在支持ONNX的推理引擎或框架上部署模型进行推理。<br>\n",
    "总之，ONNX作为一个开放和跨平台的神经网络模型表示格式，极大地促进了深度学习模型的可移植性和可访问性。它允许研究人员和开发者更加灵活地选择工具和平台， 加速了模型从研究到使用的过程。<br>\n",
    "注意本目录中文件VEXOverUnder.onnx的后缀，表示这是一个ONNX模型文件，其实就是经过微调的ONNX格式的YOLOv3网络，在后续程序分析时，将介绍怎样被变换为适合TensorRT推理的格式。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7)微调 Fine-tuning：<br>\n",
    "微调是指在一个已经在大规模数据集上预训练过的模型基础上，使用目标任务的特定数据集再次进行训练，以调整模型的参数，使模型能够更好地适应并解决目标任务。<br>\n",
    "利用预训练模型：Fine-tuning通常基于一个已经在大规模数据集上预训练过的模型，如ImageNet上的ResNet、VGG等。这些预训练模型已经学习到了丰富的特征表示，能够提供一个很好的起点。<br>\n",
    "适应特定任务：通过在目标任务的特定数据集上进行Fine-tuning，模型能够学习到与任务相关的特定特征，从而更好地适应并解决目标任务。<br>\n",
    "调整模型参数：在Fine-tuning过程中，模型的参数会根据目标任务的数据集进行调整，以优化模型在目标任务上的性能。<br>\n",
    "Fine-tuning的方法通常包括以下几个步骤：<br>\n",
    "选择预训练模型：根据目标任务的性质和数据集的特点，选择一个合适的预训练模型作为起点。<br>\n",
    "准备数据集：准备目标任务的训练集、验证集和测试集，并进行必要的数据预处理和增强。<br>\n",
    "加载预训练模型：加载选定的预训练模型，并确定需要Fine-tuning的层数。通常，可以选择微调整个模型或仅微调部分层。<br>\n",
    "修改模型结构（如果需要）：根据目标任务的需求，对预训练模型的结构进行必要的修改，如修改输出层的神经元数量等。<br>\n",
    "设置训练参数：设置训练过程中的超参数，如学习率、批次大小、训练轮数等。<br>\n",
    "进行Fine-tuning：使用目标任务的训练集对模型进行Fine-tuning，通过反向传播算法和梯度下降算法更新模型的参数。<br>\n",
    "验证和测试：使用验证集和测试集对Fine-tuned模型进行评估，以验证模型在目标任务上的性能。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.VAIC_23_24程序的概要(Jetson的python程序和Brian的C++程序)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jetson的python程序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python成为人工智能（AI）编程首选的原因主要包括：<br>\n",
    "其简洁易读的语法使学习和使用变得简单；<br>\n",
    "拥有丰富的第三方库如Scikit-learn、Pandas和NumPy等 以及深度神经网络开发平台TensorFlow和PyTorch能够支持复杂的AI项目；<br>\n",
    "开源免费的特性降低了使用成本；以及一个活跃的社区为开发者提供广泛的支持。<br>\n",
    "此外，Python的跨平台性和强大的数据可视化能力(matplotlib,OpenCV等)也大大增强了其在快速原型开发中的适用性。 这些因素共同推动了Python在AI领域的广泛应用。<br>\n",
    "C++编译程序已为广大VEX 5的用户熟知，这里不必赘述。仅对于其差异简单比较。\n",
    "Python相对于C++有以下主要缺点：<br>\n",
    "性能：Python运行速度通常慢于C++；<br>\n",
    "内存效率：Python的内存消耗较高，内存控制不如C++精细；<br>\n",
    "并发处理：Python的全局解释器锁限制了其多线程性能， 而C++提供更强的并发支持；<br>\n",
    "实时性：Python不适合需要高度实时性的应用；系统访问：<br>\n",
    "C++提供更深层次的系统级访问能力；简而言之，对于需要高性能和复杂系统控制的应用，C++是更合适的选择。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/python1.jpg\" width=\"500\" height=\"150\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jetson AI程序(python)的组成\n",
    "打开VAIC软件包，进入JetsonExample目录，可以看到以下python文件，这里一并给出功能的简单说明："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/mulu.jpg\" width=\"500\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetson python文件的说明：<br>\n",
    ".common.py Jetson在视频物体识别时，调用GPU(cuda)进行高速推理的程序。由由NVIDIA提供。<br>\n",
    ".data_processing.py 也是由NVIDIA提供，对摄像头采集的图像进行前置处理，通过YOLOv3神经网络提取目标物体的形状、颜色以及位置信息，对这些信息进行后置处理的程序。<br>\n",
    ".filter.py是对GPS实时数据进行滤波平滑处理的程序。<br>\n",
    ".model.py 变换和加载YOLOv3模型，进行目标物识别推理过程。<br>\n",
    ".overunder.py是控制机器人运动的主程序，被设计成为自动执行，机器人系统加电后，程序自动启动，检测摄像头、WI-FI、 VEX GPS，VEX Brain连接，加载YOLOv3，接收摄像头的图像，通过YOLOv3进行推理，识别场景物体，对识别物体信息进行后处理并将物体位置和距离信息 发送给Brain，由Brain根据竞赛规划选择目标物，利用目标物位置和距离信息控制机器人运动。<br>\n",
    ".V5Comm.py Jetson将检测到的目标物体位置和深度信息进行打包发送到VEX Brain通信程序。<br>\n",
    ".V5MapPosition.py 计算目标物对计算机器人旋转中心的位置并根据VEX GPS坐标定位机器人赛场上的位置的程序。<br>\n",
    ".V5Position.py是接收和处理Brain发送的VEX GPS检测的位置坐标数据。<br>\n",
    ".V5Web.py是将机器人的运动状态和摄像机图像通过Web进行远程可视化显示的程序。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其他辅助文件：<br>\n",
    ".camera_offsets.json 摄像机安装位置与机器人回转中心的坐标偏移、使用的长度量纲、与纵轴的偏角，与横轴的偏角，用于校准摄像机识别物体坐标和距离的计算。以上数据需要竞赛者根据摄像机实际安装情况测量计入。<br>\n",
    ".gps_offsets.json VEX GPS安装位置与机器人回转中心的坐标偏移、使用的长度量纲、与纵轴的偏角，用于校准识别物体在竞赛场地坐标和距离的计算。以上数据需要竞赛者根据GPS实际安装情况测量计入。<br>\n",
    ".abels.txt 三色球分类标识。<br>\n",
    ".VEXOverUnder.onnx  YOLOv3的onnx格式的镜像，用于在程序中转换为NVIDIA .engine格式，以实现TensorRT高速推理进行。<br>\n",
    ".README.md 对程序进行简单说明的MarkDown文件。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brian的C++程序\n",
    "打开VAIC软件包，进入V5Example目录，在ai_demo次目录下，可以看到src下的C++和include下的H文件，这里一并给出功能的简单说明："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/V5目录.png\" width=\"500\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aidemo下包含Brian端C++全部控制程序，由以下.cpp及.h文件组成：<br>\n",
    "其中<br>\n",
    ".ai_jetson.cpp和ai_jetson.h,定义与Jetson通讯功能有关的函数。<br>\n",
    ".ai_function.cpp和ai_function.h,定义根据Jetson视觉识别目标类别和位置坐标，控制机器人运动有关的函数。<br>\n",
    ".ai_robot_link.cpp和ai_robot_link.h,定义了自主交互竞赛阶段两台机器人为进行协调运动的通讯功能函数。<br>\n",
    ".dashboard.cpp和ai_jetson.h,定义在Brian屏幕上显示Jetson和ai_robot_link交互动态数据的函数。<br>\n",
    ".main.cpp,主控程序及程序入口。<br>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
