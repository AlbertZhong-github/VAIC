{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  What is VAIC\n",
    "VAIC, based on the regulations, robot structural materials, motion components, control hardware, software development platforms, and sensors of the V5 Robotics Competition, has introduced NVIDIA's Jetson edge computing platform's hardware and software. This integration has enabled the full automation and intelligence of the V5 Robotics Competition, allowing the VEX Robotics Competition to follow the current rapid proliferation and development of AI technology.<br>\n",
    "## VAIC facilitates the technological upgrade of equipment and hardware to achieve AI integration：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1)Introduction of the Jetson Nano edge computing platform: \n",
    "Jetson Nano is a small embedded industrial-grade computer using Ubuntu 18.04 LTS as its operating system and equipped with a GPU-accelerated chip. It serves as the computing platform for the AI functions of VAIC. NVIDIA Jetson Nano is a compact yet powerful AI computing device designed to deliver high-performance AI inference capabilities for various edge computing applications.\n",
    "\n",
    "It features a quad-core ARM Cortex-A57 CPU and a 128-core Maxwell GPU, supporting a variety of modern AI frameworks such as TensorFlow, PyTorch, and OpenCV. Jetson Nano is suitable for applications like robotics, smart cameras, and IoT devices, offering up to 472 GFLOPs of processing power, making it an ideal platform for developers and researchers working on AI projects.\n",
    "\n",
    "Jetson Nano also comes with NVIDIA's TensorRT inference acceleration software. NVIDIA's TensorRT is a high-performance deep learning inference engine designed for deployment in production environments. TensorRT can significantly improve inference speed and efficiency, optimized for NVIDIA GPUs. It reduces the computational resources required while maintaining high precision by optimizing network models. TensorRT is particularly well-suited for tasks such as image recognition and natural language processing, widely used in automotive, robotics, gaming, cloud computing, and other fields.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/jetson-nano.jpg\" width=\"500\" height=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Figure 1. Jetson Nano Edge Computing Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)Selection of Intel RealSense Stereo Depth Camera：\n",
    "The Intel RealSense stereo depth camera is the visual system foundational to intelligent cognitive behaviors such as environmental localization, object recognition and its position and distance determination, and motion path planning in competition venues.\n",
    "\n",
    "The Intel RealSense D435 camera uses stereo vision technology for distance measurement. It is equipped with two infrared cameras and an infrared laser projector, which can create depth images.\n",
    "\n",
    "The D435 calculates distance by measuring the reflection time of infrared light emitted by the laser projector on objects, achieving precise depth measurement of the scene.\n",
    "\n",
    "This technology allows the D435 to capture finer depth details, with an effective range from 0.2 meters up to a maximum of 10 meters. Additionally, the D435 supports various depth resolutions and frame rate configurations, and it is also equipped with a high-resolution RGB camera to assess the shape and color of objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/Intel435.jpg\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 2. Intel RealSense Stereo Vision Camera for Distance Measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3)Introduction of a YOLOv3-based visual deep neural network："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "YOLOv3 (You Only Look Once version 3) is a real-time object detection system developed by Joseph Redmon and other researchers. It can detect multiple objects and their categories in an image in a single forward pass. Compared to previous versions, YOLOv3 has significant improvements in both speed and accuracy.<br>\n",
    "\n",
    "Key Features:<br>\n",
    "\n",
    "Speed and Accuracy: YOLOv3 achieves real-time object detection while maintaining high accuracy.\n",
    "Darknet-53: YOLOv3 utilizes a new convolutional network architecture, Darknet-53, which is deeper and has more parameters than the previous Darknet-19, resulting in higher detection accuracy.\n",
    "Multi-Scale Detection: YOLOv3 makes predictions at three different scales, enhancing its ability to detect small objects.<br><br>\n",
    "Class Prediction: It uses logistic regression to predict different object categories.\n",
    "Anchor Mechanism: By learning anchors during training to predict bounding boxes, the model's stability and generalization capability are improved.<br><br>\n",
    "Anchor Mechanism: By learning anchors during training to predict bounding boxes, the model's stability and generalization capability are improved.<br><br>\n",
    "Due to YOLOv3's open-source nature and highly optimized implementation, it has been widely adopted in both academia and industry. Currently, breakthroughs in artificial intelligence technology are primarily driven by the application of deep neural networks. The introduction and application of YOLOv3 is a significant milestone in the AI integration of the VEX-5 Robotics Competition.<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Below is the overall hardware structure provided by VAIC, and we will explain the functions of each part and their interrelations.\n",
    "\n",
    "The left side of the diagram shows the original hardware functional modules of VEX, while the right side shows the newly added AI hardware functional modules. The colored blocks in the lower right corner of the diagram indicate the types of connecting wires for each module, corresponding to the colors of the connecting lines in the diagram. It can be seen that the Jetson Nano is powered via the red VEX 3-Wire Connector to Barrel plug Cable.\n",
    "\n",
    "The VEX GPS detects the robot's current position in the arena and uploads it to the Jetson Nano via the USB C Cable. Similarly, the positional data of targets detected by the Jetson Nano's vision system is transmitted to the VEX Brain via the Micro USB Cable.\n",
    "\n",
    "The AI section on the right side of the diagram shows that the Jetson Nano needs to connect to four hardware components:\n",
    "\n",
    "MicroSD Card: A MicroSD Card flashed with the vex_ai.img image file provided by VEX AI, containing the Ubuntu 18 operating system and all software required to run on the Jetson Nano.\n",
    "\n",
    "Intel WI-FI module is a hardware module for Internet communication, which connects to WI-FI, along with two matching transmitting and receiving antennas, providing support for Internet connection in application development and remote display functionality for off-site devices not represented in the diagram.\n",
    "\n",
    "Intel RealSense Depth Camera: As previously described, a stereo depth camera that captures real-time environmental images.\n",
    "\n",
    "VEX GPS Sensor: A GPS sensor provided by VEX that scans the field strip barcode through the camera, calculates the robot's position on the field, and uploads it to the program running on the Jetson Nano for use in transforming coordinates from the visual scene to the competition field's world coordinates.\n",
    "\n",
    "The above is a brief explanation of the VAIC hardware components. Next, we will provide a detailed introduction to the VAIC software system. To integrate with the Jetson Nano edge computing platform, some modifications will be needed in the original VEX Brain software programming. These will be covered when we explain the software for both the Jetson Nano and the VEX Brain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/VAIC.jpg\" width=\"600\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3. Hardware System Composition for the VAIC 2023-2024 Competition Projects"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
